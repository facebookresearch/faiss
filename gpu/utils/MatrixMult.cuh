/bin /boot /chef_reboot_override /chef_reboot_required /chef_reboot_trigger /data /dev /etc /fblearner_canary_tmp /fblearner_tmp /gfsai-bistro-east /gfsai-bistro-oregon /gfsai-east /gfsai-flash-east /gfsai-oregon /home /hphp /lib /lib64 /lost+found /mcrouter-web /media /mnt /opt /proc /root /run /sbin /sftp /srv /sys /tmp /usr /var /version-web AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h Copyright (c) 2015-present, Facebook, Inc. AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h All rights reserved. AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h This source code is licensed under the CC-by-NC license found in the AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h LICENSE file in the root directory of this source tree. An additional grant AutoTune.cpp AutoTune.h AuxIndexStructures.cpp AuxIndexStructures.h benchs BinaryCode.cpp BinaryCode.h c Clustering.cpp Clustering.h example_makefiles FaissAssert.h faiss.h faiss.py gpu hamming.cpp hamming.h Heap.cpp Heap.h Index.cpp IndexFlat.cpp IndexFlat.h Index.h index_io.cpp index_io.h IndexIVF.cpp IndexIVF.h IndexIVFPQ.cpp IndexIVFPQ.h IndexLSH.cpp IndexLSH.h IndexNested.cpp IndexNested.h IndexPQ.cpp IndexPQ.h INSTALL knngraph_nndescent.cpp knngraph_nndescent.h lua Makefile #MetaIndexes.cpp# MetaIndexes.cpp #MetaIndexes.h# MetaIndexes.h PolysemousTraining.cpp PolysemousTraining.h #ProductQuantizer.cpp# ProductQuantizer.cpp ProductQuantizer.h python python_history README scripts shipit-hack.bash shipit-hack.bash~ swigfaiss.swig TARGETS tests tutorial utils.cpp utils.h VectorTransform.cpp VectorTransform.h of patent rights can be found in the PATENTS file in the same directory. benchs/ c/ example_makefiles/ gpu/ lua/ python/ scripts/ tests/ tutorial/
// Copyright 2004-present Facebook. All Rights Reserved.

#pragma once

#include <cublas_v2.h>
#include "Float16.cuh"
#include "Tensor.cuh"

namespace faiss { namespace gpu {

class DeviceMemory;

/// C = alpha * A * B + beta * C
/// Expects row major layout, not fortran/blas column major!
void runMatrixMult(Tensor<float, 2, true>& c, bool transC,
                   Tensor<float, 2, true>& a, bool transA,
                   Tensor<float, 2, true>& b, bool transB,
                   float alpha,
                   float beta,
                   cublasHandle_t handle,
                   cudaStream_t stream);

#ifdef FAISS_USE_FLOAT16
/// C = alpha * A * B + beta * C
/// Expects row major layout, not fortran/blas column major!
void runMatrixMult(Tensor<half, 2, true>& c, bool transC,
                   Tensor<half, 2, true>& a, bool transA,
                   Tensor<half, 2, true>& b, bool transB,
                   float alpha,
                   float beta,
                   cublasHandle_t handle,
                   cudaStream_t stream);
#endif

/// C_i = alpha * A_i * B_i + beta * C_i
/// where `i` is the outermost dimension, via iterated gemm
/// Expects row major layout, not fortran/blas column major!
void runIteratedMatrixMult(Tensor<float, 3, true>& c, bool transC,
                           Tensor<float, 3, true>& a, bool transA,
                           Tensor<float, 3, true>& b, bool transB,
                           float alpha,
                           float beta,
                           cublasHandle_t handle,
                           cudaStream_t stream);

/// C_i = alpha * A_i * B_i + beta * C_i
/// where `i` is the outermost dimension, via batched gemm
/// Expects row major layout, not fortran/blas column major!
void runBatchMatrixMult(Tensor<float, 3, true>& c, bool transC,
                        Tensor<float, 3, true>& a, bool transA,
                        Tensor<float, 3, true>& b, bool transB,
                        float alpha,
                        float beta,
                        DeviceMemory& mem,
                        cublasHandle_t handle,
                        cudaStream_t stream);

} } // namespace
