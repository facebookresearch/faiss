version: 2.1

executors:
  linux-x86_64-cpu:
    docker:
      - image: continuumio/miniconda3
    resource_class: medium+
  linux-arm64-cpu:
    environment:
      CONDA_ARCH: Linux-aarch64
    machine:
      image: ubuntu-2004:current
    resource_class: arm.medium
  macosx-x86_64-cpu:
    environment:
      CONDA_ARCH: MacOSX-x86_64
    macos:
      xcode: 11.7.0  # max supported for conda build, https://circleci.com/docs/using-macos#supported-xcode-versions
  macosx-arm64-cpu:
    environment:
      CONDA_ARCH: MacOSX-arm64
    macos:
      xcode: 14.2.0 # minimum supported for M1
    resource_class: macos.m1.large.gen1
  windows-x86_64-cpu:
    machine:
      image: windows-server-2019-vs2019:stable
      resource_class: windows.medium
      shell: bash.exe

jobs:
  format:
    docker:
      - image: ubuntu:22.04
    steps:
      - checkout
      - run:
          name: Install clang-format
          command: |
            apt-get update
            apt-get install -y git-core clang-format-11
      - run:
          name: Verify clang-format
          command: |
             git ls-files | grep -E  '\.(cpp|h|cu|cuh)$' | xargs clang-format-11 -i
             if git diff --quiet; then
               echo "Formatting OK!"
             else
               echo "Formatting not OK!"
               echo "------------------"
               git --no-pager diff --color
               exit 1
             fi

  build_conda:
    parameters:
      exec:
        type: executor
    executor: << parameters.exec >>
    environment:
      OMP_NUM_THREADS: 10
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            if [ -n "${CONDA_ARCH}" ]
            then
              curl https://repo.anaconda.com/miniconda/Miniconda3-latest-${CONDA_ARCH}.sh --output miniconda.sh
              bash miniconda.sh -b -p $HOME/miniconda
              ~/miniconda/bin/conda init
            fi
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build
      - run:
          name: Build/test
          no_output_timeout: 30m
          command: |
            cd conda
            conda build faiss --python 3.10 -c pytorch

  deploy_conda:
    parameters:
      label:
        type: string
        default: main
      exec:
        type: executor
    executor: << parameters.exec >>
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            if [ -n "${CONDA_ARCH}" ]
            then
              curl https://repo.anaconda.com/miniconda/Miniconda3-latest-${CONDA_ARCH}.sh --output miniconda.sh
              bash miniconda.sh -b -p $HOME/miniconda
              ~/miniconda/bin/conda init
            fi
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build anaconda-client
            conda config --set anaconda_upload yes
      - run:
          name: Build/test/upload
          no_output_timeout: 30m
          environment:
            PACKAGE_TYPE: <<parameters.label>>
          command: |
            cd conda
            conda build faiss --user pytorch --label <<parameters.label>> -c pytorch

  deploy_linux_gpu:
    parameters:
      label:
        type: string
        default: main
      cuda:
        type: string
      cuda_archs:
        type: string
      compiler_version:
        type: string
    machine:
      resource_class: gpu.nvidia.medium
      image: ubuntu-2004-cuda-11.4:202110-01
      docker_layer_caching: true
    steps:
      - checkout
      - run:
          name: Build packages
          command: |
            docker build -t faiss -f conda/Dockerfile.cuda<<parameters.cuda>> .
            docker run --gpus all \
              -e PACKAGE_TYPE="<<parameters.label>>" \
              -e CUDA_ARCHS="<<parameters.cuda_archs>>" \
              -e ANACONDA_API_TOKEN=$ANACONDA_API_TOKEN \
              faiss \
              conda build faiss-gpu --variants '{ "cudatoolkit": "<<parameters.cuda>>", "c_compiler_version": "<<parameters.compiler_version>>", "cxx_compiler_version": "<<parameters.compiler_version>>" }' \
                --user pytorch --label <<parameters.label>> -c pytorch
          no_output_timeout: 60m

  deploy_linux_gpu_v2:
    parameters:
      label:
        type: string
        default: main
      cuda:
        type: string
      cuda_archs:
        type: string
      compiler_version:
        type: string
    machine:
      resource_class: gpu.nvidia.medium
      image: linux-cuda-11:2023.02.1
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh --output miniconda.sh
            bash miniconda.sh -b -p $HOME/miniconda
            ~/miniconda/bin/conda init
      - run:
          name: Install conda build tools
          command: |
            conda update -y conda
            conda install -y -q conda-build 
            # anaconda-client
            # conda config --set anaconda_upload yes
      - run:
          name: Build/test/upload
          no_output_timeout: 60m
          environment:
            PACKAGE_TYPE: <<parameters.label>>
            CUDA_ARCHS: <<parameters.cuda_archs>>
          command: |
            cd conda
            conda build faiss-gpu --variants '{ "cudatoolkit": "<<parameters.cuda>>", "c_compiler_version": "<<parameters.compiler_version>>", "cxx_compiler_version": "<<parameters.compiler_version>>" }' \
                --user pytorch --label <<parameters.label>> -c pytorch -c nvidia

  build_cmake:
    parameters:
      exec:
        type: executor
      opt_level:
        type: string
        default: generic
    executor: << parameters.exec >>
    environment:
      OMP_NUM_THREADS: 10
      MKL_THREADING_LAYER: GNU
    steps:
      - checkout
      - run: 
          name: Install conda
          command: |
            if [ -n "${CONDA_ARCH}" ]
            then
              curl https://repo.anaconda.com/miniconda/Miniconda3-latest-${CONDA_ARCH}.sh --output miniconda.sh
              bash miniconda.sh -b -p $HOME/miniconda
              ~/miniconda/bin/conda init
            fi
      - run: 
          name: Set up environment
          command: |
            conda update -y -q conda
            conda install -y -q cmake make swig mkl numpy scipy pytest gxx_linux-64
            conda install -y -q pytorch -c pytorch
      - run:
          name: Build faiss library
          no_output_timeout: 30m
          command: |
            source ~/.bashrc
            cmake -B build -DBUILD_TESTING=ON -DFAISS_ENABLE_GPU=OFF \
                  -DFAISS_OPT_LEVEL=<< parameters.opt_level >> \
                  -DFAISS_ENABLE_C_API=ON -DPYTHON_EXECUTABLE=$(which python3)\
                  -DCMAKE_BUILD_TYPE=Release -DBLA_VENDOR=Intel10_64_dyn .
            make -k -C build -j$(nproc) faiss
      - when:
          condition:
            equal: [ "avx2", << parameters.opt_level >> ]
          steps:
            - run:
                name: Build faiss_avx2 library
                no_output_timeout: 30m
                command: make -k -C build -j$(nproc) faiss_avx2 swigfaiss_avx2
      - run:
          name: Test faiss library
          command: |
            make -C build -j$(nproc) faiss_test
            export GTEST_OUTPUT="xml:$(realpath .)/test-results/googletest/"
            make -C build test
      - run:
          name: Build python extension
          command: |
            make -C build -j$(nproc) swigfaiss
            cd build/faiss/python
            python3 setup.py build
      - run:
          name: Test python extension
          command: |
            export PYTHONPATH="$(ls -d ./build/faiss/python/build/lib*/)"
            pytest --junitxml=test-results/pytest/results.xml tests/test_*.py
            pytest --junitxml=test-results/pytest/results-torch.xml tests/torch_*.py
      - store_test_results:
          path: test-results
      - run:
          name: Build C API
          command: |
            make -k -C build -j faiss_c

  build_linux_gpu:
    machine:
      resource_class: gpu.nvidia.medium
      image: ubuntu-2004-cuda-11.4:202110-01
      docker_layer_caching: true
    steps:
      - checkout
      - run:
          name: Build/test
          command: |
            docker build -t faiss -f .circleci/Dockerfile.faiss_gpu .
            docker run --gpus all faiss make -C build test
            docker run --gpus all faiss sh -c '(pwd; find)'
            docker run --gpus all faiss sh -c '(cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "test_*"'
            docker run --gpus all faiss sh -c '(cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "torch_*.py"'
          no_output_timeout: 60m

  build_linux_gpu_v2:
    machine:
      resource_class: gpu.nvidia.medium
      image: linux-cuda-11:2023.02.1
    steps:
      - checkout
      - run:
          name: Install conda
          command: |
            curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh --output miniconda.sh
            bash miniconda.sh -b -p $HOME/miniconda
            ~/miniconda/bin/conda init
      - run: 
          name: Set up environment
          command: |
            conda update -y -q conda
            conda install -y -q cmake make swig mkl numpy scipy pytest gxx_linux-64
            conda install -y -q pytorch -c pytorch
      - run:
          name: Build
          no_output_timeout: 60m
          command: |
            source ~/.bashrc
            cmake -B build \
                    -DFAISS_ENABLE_GPU=ON \
                    -DFAISS_ENABLE_C_API=ON \
                    -DFAISS_ENABLE_PYTHON=ON \
                    -DBUILD_TESTING=ON \
                    -DCMAKE_CUDA_FLAGS="-gencode arch=compute_75,code=sm_75" \
                    .
            make -C build -j8
      - run:
          name: Test
          command: |
            make -C build test
            (cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "test_*"'
            (cd build/faiss/python; python3 setup.py install) && cp tests/common_faiss_tests.py faiss/gpu/test && python3 -m unittest discover -s faiss/gpu/test -p "torch_*.py"'

workflows:
  version: 2
  build:
    jobs:
      - format:
          name: Format
      - build_cmake:
          name: Linux x86_64 (cmake)
          exec: linux-x86_64-cpu
      - build_cmake:
          name: Linux x86_64 w/ AVX2 (cmake)
          exec: linux-x86_64-cpu
          opt_level: "avx2"
      - build_linux_gpu:
          name: Linux x86_64 GPU (cmake)
          requires:
            - Linux x86_64 (cmake)
      - build_conda:
          name: Linux x86_64 (conda)
          exec: linux-x86_64-cpu
      - build_conda:
          name: OSX x86_64 (conda)
          exec: macosx-x86_64-cpu
      - build_conda:
          name: Windows (conda)
          exec: windows-x86_64-cpu
      - build_conda:
          name: OSX arm64 (conda)
          exec: macosx-arm64-cpu
      - build_conda:
          name: Linux arm64 (conda)
          exec: linux-arm64-cpu
      - deploy_conda:
          name: Linux x86_64 packages
          exec: linux-x86_64-cpu
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - deploy_linux_gpu:
          name: Linux GPU packages (CUDA 11.3)
          cuda: "11.3"
          cuda_archs: "60;61;70;72;75;80;86"
          compiler_version: "9.3"
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - deploy_conda:
          name: Windows x86_64 packages
          exec: windows-x86_64-cpu
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - deploy_conda:
          name: OSX x86_64 packages
          exec: macosx-x86_64-cpu
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - deploy_conda:
          name: OSX arm64 packages
          exec: macosx-arm64-cpu
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/
      - deploy_conda:
          name: Linux arm64 packages
          exec: linux-arm64-cpu
          filters:
            tags:
              only: /^v.*/
            branches:
              ignore: /.*/

  nightly:
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - main
    jobs:
      - deploy_conda:
          name: Linux x86_64 nightlies
          exec: linux-x86_64-cpu
          label: nightly
      - deploy_linux_gpu:
          name: Linux x86_64 GPU nightlies (CUDA 11.3)
          cuda: "11.3"
          cuda_archs: "60;61;70;72;75;80;86"
          compiler_version: "9.3"
          label: nightly
      - deploy_conda:
          name: Windows x86_64 nightlies
          exec: windows-x86_64-cpu
          label: nightly
      - deploy_conda:
          name: OSX x86_64 nightlies
          exec: macosx-x86_64-cpu
          label: nightly
      - deploy_conda:
          name: OSX arm64 nightlies
          exec: macosx-arm64-cpu
          label: nightly
      - deploy_conda:
          name: Linux arm64 nightlies
          exec: linux-arm64-cpu
          label: nightly
